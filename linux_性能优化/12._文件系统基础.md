# 文件系统基础

## inode和dentry

- inode: 每个文件(包括目录)都有各自的inode，记录文件的元数据信息。inode存储与磁盘的inode区，每个大约128/256字节。**在内存中会有inode缓存**。
- dentry：将文件名与inode号关联，将自己与其它dentry关联形成树形结构。处于内存中。

![image](https://github.com/ingangi/blog/blob/master/img/inode_dentry.png)

## vfs架构

![image](https://github.com/ingangi/blog/blob/master/img/vfs.png)

- 注意区分page cache、buffer、inode cache、dentry cache.
- 注意区分不同的文件系统，磁盘、内存、网络等；

## 文件系统I/O

### 缓冲/非缓冲

这里指的是**glibc**的缓存！

- 缓冲I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。
- 非缓冲I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。

### 直接/非直接

- 直接I/O，是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件。（指定 O_DIRECT 标志）
- 非直接I/O，正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘。（默认）
- 裸IO，跳过文件系统读写磁盘。

### 阻塞/非阻塞

- 阻塞I/O，是指应用程序执行I/O操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务。（默认）
- 非阻塞I/O，是指应用程序执行I/O操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果。(epoll等多路复用属于非阻塞I/O) （设置 O_NONBLOCK 标志）

### 同步/异步

- 同步I/O，是指应用程序执行I/O操作后，要一直等到整个I/O完成后，才能获得I/O响应。

> 设置O_SYNC 或者 O_DSYNC标志，就代表同步I/O。如果设置了O_DSYNC，就要等文件数据写入磁盘后，才能返回；而O_SYNC，则是在O_DSYNC基础上，要求文件元数据也要写入磁盘后，才能返回。

- 异步I/O，是指应用程序执行I/O操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次I/O完成后，响应会用事件通知的方式，告诉应用程序。

> 设置了O_ASYNC选项后，相应的I/O就是异步I/O。这样，内核会再通过SIGIO或者SIGPOLL，来通知进程文件是否可读写。

### 晴天霹雳！非阻塞I/O != 异步I/O !

我们平时很少用异步I/O! select + read严格来说是同步I/O，关键在于**recvfrom**这个系统调用的行为是否异步！

> non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。

## 性能观测

### 磁盘和inode

```
// 磁盘空间使用情况
$ df 
Filesystem     1K-blocks     Used Available Use% Mounted on
/dev/sda3       49997976 21901072  28096904  44% /
devtmpfs          915784        0    915784   0% /dev

// inode使用情况
$ df -i
Filesystem       Inodes  IUsed    IFree IUse% Mounted on
/dev/sda3      25011200 519686 24491514    3% /
devtmpfs         228946    395   228551    1% /dev
```

### inode cache和dentry cache

> 内核使用Slab机制，管理目录项和索引节点的缓存。/proc/meminfo只给出了Slab的整体大小，具体到每一种Slab缓存，还要查看/proc/slabinfo这个文件。

```
$ cat /proc/slabinfo | grep -E '^#|dentry|inode' 
# name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <limit> <batchcount> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail> 
xfs_inode              0      0    960   17    4 : tunables    0    0    0 : slabdata      0      0      0 
... 
ext4_inode_cache   32104  34590   1088   15    4 : tunables    0    0    0 : slabdata   2306   2306      0hugetlbfs_inode_cache     13     13    624   13    2 : tunables    0    0    0 : slabdata      1      1      0 
sock_inode_cache    1190   1242    704   23    4 : tunables    0    0    0 : slabdata     54     54      0 
shmem_inode_cache   1622   2139    712   23    4 : tunables    0    0    0 : slabdata     93     93      0 
proc_inode_cache    3560   4080    680   12    2 : tunables    0    0    0 : slabdata    340    340      0  // xx文件系统的inode cache
inode_cache        25172  25818    608   13    2 : tunables    0    0    0 : slabdata   1986   1986      0  // 磁盘文件系统的inode cache
dentry             76050 121296    192   21    1 : tunables    0    0    0 : slabdata   5776   5776      0  //dentry cache
```

#### slabtop
```
# 按下c按照缓存大小排序，按下a按照活跃对象数排序 
$ slabtop 
Active / Total Objects (% used)    : 277970 / 358914 (77.4%) 
Active / Total Slabs (% used)      : 12414 / 12414 (100.0%) 
Active / Total Caches (% used)     : 83 / 135 (61.5%) 
Active / Total Size (% used)       : 57816.88K / 73307.70K (78.9%) 
Minimum / Average / Maximum Object : 0.01K / 0.20K / 22.88K 

  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME 
69804  23094   0%    0.19K   3324       21     13296K dentry 
16380  15854   0%    0.59K   1260       13     10080K inode_cache 
58260  55397   0%    0.13K   1942       30      7768K kernfs_node_cache 
   485    413   0%    5.69K     97        5      3104K task_struct 
  1472   1397   0%    2.00K     92       16      2944K kmalloc-2048 
```